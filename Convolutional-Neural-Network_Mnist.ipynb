{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) are a class of deep neural networks, most commonly used in computer vision applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras using tensorflow backend\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "print('keras using %s backend'%keras.backend.backend())\n",
    "import matplotlib.pyplot as graph\n",
    "%matplotlib inline \n",
    "graph.rcParams['figure.figsize'] = (15,5)\n",
    "graph.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "graph.rcParams[\"font.size\"] = '12'\n",
    "graph.rcParams['image.cmap']  ='rainbow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now importing the dataset, and split it into the training, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X: (6400, 28, 28), train_Y: (6400,)valid_X: (1600, 28, 28), valid_Y: (1600,)test_X: (2000, 28, 28), test_Y (2000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "#This is the training data with 6400 samples\n",
    "train_X = mnist.load_data()[0][0][:6400].astype('float32')\n",
    "train_Y = mnist.load_data()[0][1][:6400]\n",
    "\n",
    "#This is the validation data, with 1600 samples\n",
    "valid_X = mnist.load_data()[1][0][:1600].astype('float32')\n",
    "valid_Y = mnist.load_data()[1][1][:1600]\n",
    "\n",
    "#This is the test data with 2000 samples \n",
    "test_X = mnist.load_data()[1][0][-2000:].astype('float32')\n",
    "test_Y = mnist.load_data()[1][1][-2000:]\n",
    "\n",
    "print('train_X:', train_X.shape, end = '')\n",
    "print(', train_Y:', train_Y.shape, end = '')\n",
    "print('valid_X:', valid_X.shape, end = '')\n",
    "print(', valid_Y:', valid_Y.shape, end = '')\n",
    "print('test_X:', test_X.shape, end = '')\n",
    "print(', test_Y', test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 6400 training samples, 1600 validation samples, and 2000 test samples.\n",
    "\n",
    "Each sample is an greyscale image - 28 pixels wide and 28 pixels high. Each pixel is really a number from 0 to 255 - 0 being fully black, 255 being fully white. When we graph the 28x28 numbers, we can see the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAEyCAYAAAB02CyCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAReUlEQVR4nO3db4xV9Z3H8c9HxpaKIEW7mNgUAqnQQiuJUDatqW0sSzQai/RBqfaJrjS7TtJHbhuj7tgVa9I/D0hNA1mWKnGNmmD906TtboA2tVmyYwWzGLRpXNQWu6KCMyNike8+mDvNZZyZ+5u5Z+bM/fp+JTeBc7787vdyhg/nz++c64gQAGRwRt0NAEBVCDQAaRBoANIg0ACkQaABSINAA5BGVx1vapu5IgAm6khEfGSkFZXsodmeZ/sR2wO2D9n+WhXjAsAIDo22oqo9tHskvSNpvqQVkn5me39EHKhofABoqe09NNuzJK2XdFtE9EfEbyQ9Junr7Y4NAONRxSHnhZJORsTzTcv2S1pWwdgAUKyKQ86zJb05bNkxSbObF9jeKGljBe8HACOqItD6Jc0ZtmyOpL7mBRGxVdJWiaucACZHFYecz0vqsv3xpmUXSeKCAIAp1XagRcSApJ2SvmN7lu3PSbpa0o52xwaA8ajqToF/lPQhSf8n6QFJ/8CUDQBTrZJ5aBHxuqQvVzEWAEwU93ICSINAA5AGgQYgDQINQBoEGoA0CDQAaRBoANIg0ACkQaABSINAA5AGgQYgDQINQBoEGoA0CDQAaRBoANIg0ACkQaABSINAA5AGgQYgDQINQBoEGoA0CDQAaRBoANIg0ACkQaABSINAA5AGgQYgDQINQBoEGoA0CDQAaRBoANIg0ACkQaABSINAA5AGgQYgDQINQBoEGoA0CDQAaXTV3QBymDFjRsuac845Zwo6OV13d3dR3VlnnVVUt2TJkqK6m266qWXN97///aKxNmzYUFT39ttvt6y5++67i8a64447iuqmm0r20Gzvsf227f7G67kqxgWA8ajykLM7Is5uvMr+GwOACnEODUAaVQbad20fsf2k7S8MX2l7o+1e270VvicA/FVVgfYtSYskXSBpq6THbS9uLoiIrRGxMiJWVvSeAHCaSgItIvZGRF9EnIiIeyU9KemKKsYGgFKTdQ4tJHmSxgaAEbUdaLbn2l5re6btLtvXSvq8pJ+33x4AlKtiYu2Zku6UtFTSu5IOSvpyRDxfwdho8rGPfaxlzQc+8IGisT772c8W1V1yySVFdXPnzm1Zs379+qKxprOXX365qG7z5s0ta9atW1c0Vl9fX1Hd/v37W9b86le/KhqrU7UdaBHxqqRVFfQCAG1hHhqANAg0AGkQaADSINAApEGgAUiDQAOQBoEGIA0CDUAajoipf1N76t90GluxYkVR3a5du1rW1PGY6wxOnTpVVHf99dcX1fX397fTzmkOHz5cVPfGG2+0rHnuuRQPk35qtKf2sIcGIA0CDUAaBBqANAg0AGkQaADSINAApEGgAUiDQAOQBoEGII0qvlMAbXrxxReL6l577bWWNRnuFNi7d29R3dGjR1vWfPGLXywa65133imq27FjR1Ed6sEeGoA0CDQAaRBoANIg0ACkQaABSINAA5AGgQYgDQINQBpMrJ0GXn/99aK6m2++uWXNlVdeWTTW008/XVS3efPmoroS+/btK6pbs2ZNUd3AwEDLmmXLlhWN9c1vfrOoDtMbe2gA0iDQAKRBoAFIg0ADkAaBBiANAg1AGgQagDQINABpEGgA0nBETP2b2lP/pu8Tc+bMKarr6+srqtuyZUtR3Q033NCy5rrrrisa64EHHiiqw/vWUxGxcqQVRXtotrtt99o+Yfsnw9ZdZvug7bds77a9oIKGAWDcSg85/yTpTkn/1rzQ9nmSdkq6TdI8Sb2SHqyyQQAoVXRzekTslCTbKyV9tGnVNZIORMTDjfU9ko7YXhoRByvuFQDG1O5FgWWS9g/9JiIGJP2hsRwAplS7jw86W9Krw5YdkzR7eKHtjZI2tvl+ADCqdgOtX9Lwy2pzJL3nElpEbJW0VeIqJ4DJ0e4h5wFJFw39xvYsSYsbywFgSpVO2+iyPVPSDEkzbM+03SXpEUnLba9vrL9d0jNcEABQh9I9tFslHZf0bUnXNX59a0S8Kmm9pE2S3pC0WtJXJ6FPAGipdNpGj6SeUdb9p6Sl1bWEdrz55puVjnfs2LHKxrrxxhuL6h58sGwq46lTp9ppBwlxLyeANAg0AGkQaADSINAApEGgAUiDQAOQBoEGIA0CDUAaBBqANPhOAYxp1qxZRXWPP/54y5pLL720aKzLL7+8qO6Xv/xlUR3Sae87BQCgExBoANIg0ACkQaABSINAA5AGgQYgDQINQBoEGoA0mFiLSixevLhlze9+97uisY4ePVpUt3v37pY1vb29RWPdc889RXV1/HvBezCxFkB+BBqANAg0AGkQaADSINAApEGgAUiDQAOQBoEGIA0CDUAa3CmAKbNu3bqiuu3btxfVzZ49u512TnPLLbcU1d13331FdYcPH26nHYyNOwUA5EegAUiDQAOQBoEGIA0CDUAaBBqANAg0AGkQaADSINAApMGdAph2li9fXlT3wx/+sGXNZZdd1m47p9myZUtR3aZNm1rW/PGPf2y3nfer9u4UsN1tu9f2Cds/aVq+0HbY7m963VZR0wAwLl2FdX+SdKektZI+NML6uRFxsrKuAGACigItInZKku2Vkj46qR0BwARVdVHgkO2XbW+3fd5IBbY3Ng5by74oEQDGqd1AOyJplaQFki6WNFvS/SMVRsTWiFg52sk8AGhX6Tm0EUVEv6ShPa4/2+6WdNj27Ijoa7s7ABiHquehDU3HYH4bgClXtIdmu6tRO0PSDNszJZ3U4GHmUUm/l/RhSZsl7YmIY5PTLgCMrmhire0eSf88bPEdkp6TdJekv5H0pqT/kPRPEfFKi/GYWIu2zZ07t2XNVVddVTRW6WO/bRfV7dq1q2XNmjVrisbCe4w6sbZ02kaPpJ5RVj8wsZ4AoFqc6wKQBoEGIA0CDUAaBBqANAg0AGkQaADSINAApEGgAUiDR3ADkk6cOFFU19VV9jyHkydbP+907dq1RWPt2bOnqO59pL1HcANAJyDQAKRBoAFIg0ADkAaBBiANAg1AGgQagDQINABpEGgA0mjra+yAyfDpT3+6qO4rX/lKy5pVq1YVjVV6B0CpZ599tmXNr3/960rfE+yhAUiEQAOQBoEGIA0CDUAaBBqANAg0AGkQaADSINAApEGgAUiDOwVQiSVLlrSs6e7uLhrrmmuuKao7//zzi+qq9O677xbVHT58uGXNqVOn2m0Hw7CHBiANAg1AGgQagDQINABpEGgA0iDQAKRBoAFIg0ADkAYTa9+nSielbtiwoaiuZNLswoULi8aqQ29vb1Hdpk2biuoee+yxdtrBBLXcQ7P9QdvbbB+y3Wd7n+3Lm9ZfZvug7bds77a9YHJbBoCRlRxydkl6SdKlks6RdKukh2wvtH2epJ2SbpM0T1KvpAcnqVcAGFPLQ86IGJDU07ToCdsvSLpY0rmSDkTEw5Jku0fSEdtLI+Jg9e0CwOjGfVHA9nxJF0o6IGmZpP1D6xrh94fGcgCYUuMKNNtnSrpf0r2NPbCzJR0bVnZM0uwR/uxG2722y86+AsA4FV/ltH2GpB2S3pE0dEmrX9KcYaVzJPUN//MRsVXS1sZYMZFmAWAsRXtoti1pm6T5ktZHxF8aqw5IuqipbpakxY3lADClSg85fyzpE5KuiojjTcsfkbTc9nrbMyXdLukZLggAqEPJPLQFkr4haYWkV2z3N17XRsSrktZL2iTpDUmrJX11MhsGgNE4YupPZ3EObWLmz5/fsuaTn/xk0Vg/+tGPiuqWLl1aVFeHvXv3tqz53ve+VzTWo48+WlTHY7OnhaciYuVIK7iXE0AaBBqANAg0AGkQaADSINAApEGgAUiDQAOQBoEGIA0CDUAafKfAJJo3b15R3ZYtW4rqVqxY0bJm0aJFRWPV4be//W1R3Q9+8IOiul/84hcta44fP96yBnmwhwYgDQINQBoEGoA0CDQAaRBoANIg0ACkQaABSINAA5AGE2uHWb16dVHdzTff3LLmM5/5TNFYF1xwQVFdHd56662ius2bN7esueuuu4rGGhgYKKoDhmMPDUAaBBqANAg0AGkQaADSINAApEGgAUiDQAOQBoEGIA0CDUAa3CkwzLp16yqtq9Kzzz7bsuaJJ54oGuvkyZNFdaWPwz569GhRHTCZ2EMDkAaBBiANAg1AGgQagDQINABpEGgA0iDQAKRBoAFIg0ADkIYjYurf1J76NwWQxVMRsXKkFS330Gx/0PY224ds99neZ/vyxrqFtsN2f9Prtqq7B4ASJfdydkl6SdKlkl6UdIWkh2x/qqlmbkSU3RwIAJOk5R5aRAxERE9E/G9EnIqIJyS9IOniyW8PAMqN+6KA7fmSLpR0oGnxIdsv295u+7zKugOAcRhXoNk+U9L9ku6NiIOSjkhaJWmBBvfYZjfWj/RnN9rutd3bXssAMLLiq5y2z5D075LmSLo6Iv4yQs35kg5LmhMRfWOMxVVOABM16lXOogc82rakbZLmS7pipDBrGAoq5rcBmHKlT6z9saRPSPpSRBwfWmh7taSjkn4v6cOSNkvaExHHqm4UAFopmYe2QNI3JK2Q9ErTfLNrJS2S9HNJfZL+R9IJSRsmsV8AGBV3CgDoNBO/UwAAOgWBBiANAg1AGgQagDQINABpEGgA0iDQAKRBoAFIg0ADkAaBBiANAg1AGgQagDQINABpEGgA0iDQAKRBoAFIg0ADkAaBBiCN0i9JqdoRSYeGLTuvsbyTdfpn6PT+pc7/DJ3evzT5n2HBaCtq+U6BkdjuHe054Z2i0z9Dp/cvdf5n6PT+pXo/A4ecANIg0ACkMZ0CbWvdDVSg0z9Dp/cvdf5n6PT+pRo/w7Q5hwYA7ZpOe2gA0BYCDUAatQea7Xm2H7E9YPuQ7a/V3dN42d5j+23b/Y3Xc3X3NBbb3bZ7bZ+w/ZNh6y6zfdD2W7Z32x51zk+dRvsMthfajqZt0W/7thpbHZHtD9re1viZ77O9z/blTeun9XYYq/86t0FdE2ub3SPpHUnzJa2Q9DPb+yPiQL1tjVt3RPxr3U0U+pOkOyWtlfShoYW2z5O0U9LfS3pc0r9IelDS39bQYysjfoYmcyPi5NS2NC5dkl6SdKmkFyVdIekh25+S1K/pvx3G6n/IlG+DWgPN9ixJ6yUtj4h+Sb+x/Zikr0v6dp29ZRYROyXJ9kpJH21adY2kAxHxcGN9j6QjtpdGxMEpb3QMY3yGjhARA5J6mhY9YfsFSRdLOlfTfDu06P+pWppS/YecF0o6GRHPNy3bL2lZTf2047u2j9h+0vYX6m5mgpZp8O9f0l9/aP+gztweh2y/bHt7Y89zWrM9X4P/Hg6oA7fDsP6HTPk2qDvQzpb05rBlxyTNrqGXdnxL0iJJF2hwDs7jthfX29KEnK3Bv/9mnbY9jkhapcH7/S7WYO/319pRC7bP1GCP9zb2wDpqO4zQf23boO5A65c0Z9iyOZL6auhlwiJib0T0RcSJiLhX0pMaPKfQaTp+e0REf0T0RsTJiPizpG5Jf2d7uobBGZJ2aPA8cndjccdsh5H6r3Mb1B1oz0vqsv3xpmUX6fTd1k4Uklx3ExNwQIN//5L+eo5zsTp7ewzNHK/7Z/09bFvSNg1eEFsfEX9prOqI7TBG/8NN2TaodSM3zg3slPQd27Nsf07S1RpM/I5ge67ttbZn2u6yfa2kz0v6ed29jabR50xJMyTNGOpd0iOSltte31h/u6RnpsuJ6GajfQbbq20vsX2G7XMlbZa0JyKGH8JNBz+W9AlJV0XE8ablnbIdRuy/1m0QEbW+JM2T9FNJAxq8/Pu1unsaZ/8fkfTfGjwcOCrpvyStqbuvFj33aPB/zeZXT2PdlyQdlHRc0h5JC+vudzyfQdIGSS80fp4OS7pP0vl19ztC/wsaPb+twUPMode1nbAdxuq/zm3AvZwA0ph25xUAYKIINABpEGgA0iDQAKRBoAFIg0ADkAaBBiANAg1AGgQagDT+H1o7VYvXZercAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use train_X[0] or ANOTHER SAMPLE e.g. train_X[1] or train_X[2]\n",
    "graph.imshow(train_X[0], cmap = 'gray',interpolation = 'nearest')\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network will use the 28x28 values of each image to predict what each image represents.\n",
    "\n",
    "As each value is between 0 and 255, we'll scale the values down by dividing by 255 (this makes it faster for the Neural Network to train).\n",
    "\n",
    "We need to reshape our data to get it working well with our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#reshape X sets so that they fit the convolutional layers\n",
    "\n",
    "#this gets the image dimensions -28\n",
    "dim = train_X[0].shape[0]\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0], dim, dim, 1)\n",
    "valid_X = valid_X.reshape(valid_X.shape[0], dim, dim, 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], dim, dim, 1)\n",
    "\n",
    "#feature scaling: scale the values so they are between 0 and 1, instead of 0 and 255\n",
    "train_X = train_X / 255\n",
    "valid_X = valid_X / 255\n",
    "test_X = test_X / 255\n",
    "\n",
    "#print the label for the first example \n",
    "print(train_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent this number as a one-hot vector, so the neural network knows it is a category. Keras can convert these labels into one-hot vectors easily with the function - to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_Y = keras.utils.to_categorical(train_Y, 10)\n",
    "valid_Y = keras.utils.to_categorical(valid_Y, 10)\n",
    "test_Y = keras.utils.to_categorical(test_Y, 10)\n",
    "\n",
    "# 10 being the number of categories (0 - 9)\n",
    "print(train_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build anoter neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a randomisation seed for replicatability \n",
    "np.random.seed(6)\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Convolutional in Convolutional Neural Networks refers the pre-processing the network can do itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(28, kernel_size = (3, 3), activation = 'relu', input_shape = (dim, dim, 1)))\n",
    "model.add(Conv2D(56, (3,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add pooling layers: Pooling layers help speed up training time and make features it detects more robos. They act by downsampling the data- reducing the data size and complexity.\n",
    "\n",
    "\n",
    "Apply dropout: Dropout is a technique to help prevent overfitting. it makes nodes 'dropout\"-- turning them off randomly. \n",
    "\n",
    "\n",
    "Flatten the data to a vector (the output of step 2 is a vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Dropout(0.125))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layers perform classification - we have extracted the features with the convolutional pre-processing\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "#more dropouts\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Output layer: Softmax outputs the probability for each category\n",
    "#the number of classes (digits 0 to 9)\n",
    "\n",
    "model.add(Dense (10, activation = tf.nn.softmax))\n",
    "\n",
    "#finally, compile \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adamax', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "#Now train it \n",
    "training_stats = model.fit(train_X, train_Y, batch_size = 128, epochs = 12, verbose = 1, validation_data = (valid_X,valid_Y))\n",
    "\n",
    "evaluation =model.evaluate(test_X, test_Y, verbose = 0)\n",
    "\n",
    "print('Test Set Evaluation: loss = %0.6f, accuracy = %0.2f' %(evaluation[0], 100 * evaluation[1]))\n",
    "\n",
    "#plot the train statistics to see how it developed over time \n",
    "accuracy, =graph.plot(training_stats.history['acc'], label = 'Accuracy')\n",
    "training_loss, =graph.plot(training_stats.history['loss'], label = 'Training Loss')\n",
    "\n",
    "graph.legend(handles = [accuracy, training_loss])\n",
    "loss = np.array(training_stats.history['loss'])\n",
    "xp = np.linspace(0, loss.shape[0], 10*loss.shape[0])\n",
    "graph.plot(xp, np.full(xp.shape, 1), c = 'k', linstyle = ':', alpha = 0.5)\n",
    "graph.plot(xp, np.full(xp.shape, 0), c = 'k', linstyle = ':', alpha = 0.5)\n",
    "graph.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test on a new sample that it hasn't seen, and see how it classifies it \n",
    "#any number between 0 - 1999\n",
    "sample = test_X[1200].reshape(dim, dim)\n",
    "\n",
    "graph.imshow(sample, cmap ='gray', interpolation = 'nearest')\n",
    "graph.show()\n",
    "\n",
    "prediction = model.predict(sample.reshape(1, dim, dim, 1))\n",
    "print('prediction: %i' %(np.argmax(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! built a convolutional neural network that is able to recognise handwritten digits with very high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
